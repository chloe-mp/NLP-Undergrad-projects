# ğŸ“š Projet S1 â€“ Indexation inversÃ©e dâ€™un corpus de textes franÃ§ais

This project builds a basic inverted index from a corpus of French documents. It allows identifying which files contain a given word, functioning like a simple keyword search engine.

---

## ğŸ§  Objective

To scan a directory of French documents and build an index that maps each word to the list of documents it appears in. This index is saved in JSON format and can be queried to find occurrences of specific terms.

---

## ğŸ›  Technologies Used

- Python
- `nltk` for tokenization
- `glob` for file system exploration
- `json` for saving/loading the index

---

## ğŸ§‘â€ğŸ’» How It Works

### 1. Load Documents

```python
documents = {}
for file in glob.glob("corpus_multi/fr/*/*"):
    documents[file] = lire_fichier(file)
```
> Loads the French text files into a dictionary.

---

### 2. Tokenize Words

```python
def decouper_mots(chaine):
    return set(word_tokenize(chaine, language='french'))
```
> Each document is tokenized into individual words. Duplicates are removed using `set()`.

---

### 3. Build Inverted Index

```python
index[mot].add(file)
```
> For each word in each document, a list of file paths is associated.

---

### 4. Save to JSON

```python
with open("index.json", "w") as w:
    json.dump(index_pour_json, w)
```
> The final index is saved to a file for future querying.

---

### 5. Load and Query

```python
with open("index.json") as f:
    index = json.load(f)

index["europÃ©enne"]
```
> Returns the list of files that contain the word â€œeuropÃ©enneâ€.

---

## ğŸ“ˆ Interpretation of Results

- You obtain a dictionary where each word is linked to the set of documents that contain it.
- This is useful for:
  - Quick keyword search
  - Analyzing term frequency and document occurrence
- It's a simple but efficient model for text indexing.

---

## ğŸ’¡ Improvements Possible

- Count occurrences per document
- Add multi-word queries
- Use TF-IDF to rank documents by relevance

---

## ğŸ‘©â€ğŸ’» Author

Created by **ChloÃ© Petridis** as part of a university project on text processing and indexing.
